{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autorelead libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import get_config\n",
    "from dataset import data_loader\n",
    "from neural_methods.model.RadarNet import RadarNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMetrics(input_data, sampFreq, B, window_size=None, use_harmonic=False, normalize=False):\n",
    "    # define goodness parameters\n",
    "    B1 = 0.75 # low cutoff\n",
    "    B2 = 3 # high cutoff\n",
    "\n",
    "    if window_size is None:\n",
    "        pulseCalcLength = len(input_data)\n",
    "    else:\n",
    "        pulseCalcLength = np.uint32(window_size/(1.0/sampFreq))\n",
    "    pulseRate_result = np.empty(len(input_data)-pulseCalcLength + 1)\n",
    "    goodnessMetric_result = np.empty(len(input_data)-pulseCalcLength + 1)\n",
    "\n",
    "    for i in range(0, len(pulseRate_result)):\n",
    "        window = input_data[i:i+pulseCalcLength]\n",
    "        # ppgFreq, ppgPower = sig.periodogram(window, fs=sampFreq, nfft=180000)\n",
    "        ppgFreq, ppgPower = sig.welch(x=window, nperseg=len(window)//3, fs=sampFreq, nfft=180000)\n",
    "        maskFreq = (ppgFreq > B1)&(ppgFreq<B2)\n",
    "        # ppgFreq = ppgFreq[maskFreq]\n",
    "        ppgPower = ppgPower * maskFreq\n",
    "        if use_harmonic:\n",
    "            # harmonic PSD\n",
    "            harmonicppgPower = ppgPower[::2]\n",
    "            harmonicppgPower = np.pad(harmonicppgPower, (0, len(ppgPower) - len(harmonicppgPower)))\n",
    "            # find peak frequency\n",
    "            peakFreq = ppgFreq[np.argmax(ppgPower + harmonicppgPower)]\n",
    "        else:\n",
    "            peakFreq = ppgFreq[np.argmax(ppgPower)]\n",
    "        pulseRate = 60.0*peakFreq\n",
    "        pulseRate_result[i] = pulseRate\n",
    "        # compute goodness\n",
    "        aroundPulseRate = (ppgFreq > peakFreq - B) & (ppgFreq < peakFreq + B)\n",
    "        withinBandpass = (ppgFreq >= B1) & (ppgFreq <= B2)\n",
    "        powerPulseRate = np.sum(ppgPower[aroundPulseRate])\n",
    "        powerAll = np.sum(ppgPower[withinBandpass])\n",
    "        if normalize:\n",
    "            goodnessMetric_result[i] = powerPulseRate / powerAll\n",
    "        else:\n",
    "            goodnessMetric_result[i] = powerPulseRate / (powerAll - powerPulseRate)\n",
    "    timestamps = np.arange(len(pulseRate_result))\n",
    "    return timestamps, goodnessMetric_result, pulseRate_result\n",
    "\n",
    "def custom_detrend(sig, Lambda):\n",
    "    \"\"\"custom_detrend(sig, Lambda) -> filtered_signal\n",
    "    This function applies a detrending filter.\n",
    "    This code is based on the following article \"An advanced detrending method with application\n",
    "    to HRV analysis\". Tarvainen et al., IEEE Trans on Biomedical Engineering, 2002.\n",
    "    *Parameters*\n",
    "      ``sig`` (1d numpy array):\n",
    "        The sig where you want to remove the trend.\n",
    "      ``Lambda`` (int):\n",
    "        The smoothing parameter.\n",
    "    *Returns*\n",
    "      ``filtered_signal`` (1d numpy array):\n",
    "        The detrended sig.\n",
    "    \"\"\"\n",
    "    signal_length = sig.shape[0]\n",
    "\n",
    "    # observation matrix\n",
    "    H = np.identity(signal_length)\n",
    "\n",
    "    # second-order difference matrix\n",
    "\n",
    "    ones = np.ones(signal_length)\n",
    "    minus_twos = -2 * np.ones(signal_length)\n",
    "    diags_data = np.array([ones, minus_twos, ones])\n",
    "    diags_index = np.array([0, 1, 2])\n",
    "    D = sp.spdiags(diags_data, diags_index, (signal_length - 2), signal_length).toarray()\n",
    "    filtered_signal = np.dot((H - np.linalg.inv(H + (Lambda ** 2) * np.dot(D.T, D))), sig)\n",
    "    return filtered_signal\n",
    "\n",
    "def pulse_rate_from_power_spectral_density(pleth_sig: np.array, FS: float,\n",
    "                                           LL_PR: float, UL_PR: float,\n",
    "                                           BUTTER_ORDER: int = 6,\n",
    "                                           DETREND: bool = False,\n",
    "                                           FResBPM: float = 0.1,\n",
    "                                           HARMONIC: bool = False,\n",
    "                                           WELCH = True) -> float:\n",
    "    \"\"\" Function to estimate the pulse rate from the power spectral density of the plethysmography sig.\n",
    "\n",
    "    Args:\n",
    "        pleth_sig (np.array): Plethysmography sig.\n",
    "        FS (float): Sampling frequency.\n",
    "        LL_PR (float): Lower cutoff frequency for the butterworth filtering.\n",
    "        UL_PR (float): Upper cutoff frequency for the butterworth filtering.\n",
    "        BUTTER_ORDER (int, optional): Order of the butterworth filter. Give None to skip filtering. Defaults to 6.\n",
    "        DETREND (bool, optional): Boolena Flag for executing cutsom_detrend. Defaults to False.\n",
    "        FResBPM (float, optional): Frequency resolution. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        pulse_rate (float): _description_\n",
    "    \n",
    "\n",
    "    Daniel McDuff, Ethan Blackford, January 2019\n",
    "    Copyright (c)\n",
    "    Licensed under the MIT License and the RAIL AI License.\n",
    "    \"\"\"\n",
    "\n",
    "    N = (60*FS)/FResBPM\n",
    "\n",
    "    # Detrending + nth order butterworth + periodogram\n",
    "    if DETREND:\n",
    "        pleth_sig = custom_detrend(pleth_sig, 100)\n",
    "    if BUTTER_ORDER:\n",
    "        [b, a] = sig.butter(BUTTER_ORDER, [LL_PR/60, UL_PR/60], btype='bandpass', fs = FS)\n",
    "        pleth_sig = sig.filtfilt(b, a, np.double(pleth_sig))\n",
    "    \n",
    "    # Calculate the PSD and the mask for the desired range\n",
    "    if WELCH:\n",
    "        F, Pxx = sig.welch(x=pleth_sig, nperseg=len(pleth_sig)//3, nfft=N, fs=FS)\n",
    "    else:\n",
    "        F, Pxx = sig.periodogram(x=pleth_sig,  nfft=N, fs=FS);  \n",
    "    FMask = (F >= (LL_PR/60)) & (F <= (UL_PR/60))\n",
    "    \n",
    "    # Calculate predicted pulse rate:\n",
    "    FRange = F * FMask\n",
    "    PRange = Pxx * FMask\n",
    "\n",
    "    if HARMONIC:\n",
    "      harmonicppgPower = PRange[::2]\n",
    "      harmonicppgPower = np.pad(harmonicppgPower, (0, len(PRange) - len(harmonicppgPower)))\n",
    "      harmonicppgPower[0] = 0\n",
    "      MaxInd = np.argmax(PRange+harmonicppgPower)\n",
    "    else:\n",
    "      MaxInd = np.argmax(PRange)\n",
    "    pulse_rate_freq = FRange[MaxInd]\n",
    "    pulse_rate = pulse_rate_freq*60\n",
    "            \n",
    "    return pulse_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    config_file = 'configs/train_configs/CogPhys_Resp_Radar_BASIC.yaml'\n",
    "    cached_path = None\n",
    "    preprocess = None\n",
    "    lr = None\n",
    "    model_file_name = None\n",
    "\n",
    "args = Args()\n",
    "config = get_config(args)\n",
    "# print('Configuration:')\n",
    "# print(config, end='\\n\\n')\n",
    "data_loader_dict = dict() # dictionary of data loaders \n",
    "train_loader = data_loader.CogPhysLoader.CogPhysLoader\n",
    "print(config.DEVICE)\n",
    "train_data_loader = train_loader(\n",
    "    name=\"train\",\n",
    "    data_path=config.TRAIN.DATA.DATA_PATH,\n",
    "    config_data=config.TRAIN.DATA,\n",
    "    device=config.DEVICE)\n",
    "data_loader_dict['train'] = DataLoader(\n",
    "    dataset=train_data_loader,\n",
    "    num_workers=2,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "print(); print()\n",
    "\n",
    "valid_loader = data_loader.CogPhysLoader.CogPhysLoader\n",
    "print(config.DEVICE)\n",
    "valid_data_loader = valid_loader(\n",
    "    name=\"valid\",\n",
    "    data_path=config.VALID.DATA.DATA_PATH,\n",
    "    config_data=config.VALID.DATA,\n",
    "    device=config.DEVICE)\n",
    "data_loader_dict['valid'] = DataLoader(\n",
    "    dataset=valid_data_loader,\n",
    "    num_workers=2,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "print(); print()\n",
    "\n",
    "test_loader = data_loader.CogPhysLoader.CogPhysLoader\n",
    "print(config.DEVICE)\n",
    "test_data_loader = test_loader(\n",
    "    name=\"test\",\n",
    "    data_path=config.TEST.DATA.DATA_PATH,\n",
    "    config_data=config.TEST.DATA,\n",
    "    device=config.DEVICE)\n",
    "data_loader_dict['test'] = DataLoader(\n",
    "    dataset=test_data_loader,\n",
    "    num_workers=4,\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader.input_preproc, test_data_loader.label_preproc, test_data_loader.input_keys, test_data_loader.label_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = config.MODEL.RADARNET.CHANNELS\n",
    "print(\"RadarNet channels: \", channels)\n",
    "model = RadarNet(channels=channels).to(config.DEVICE).eval()\n",
    "model.load_state_dict(torch.load('runs/exp/again_resp_radar_1e-3/PreTrainedModels/CogPhys_rPPG_ch3_PhysNet_Epoch9.pth', \n",
    "                                 map_location=config.DEVICE))\n",
    "# model.load_state_dict(torch.load('runs/exp/resp_radar_1e-3/PreTrainedModels/CogPhys_rPPG_ch3_PhysNet_Epoch9.pth', \n",
    "#                                  map_location=config.DEVICE))\n",
    "# Enable dropout only\n",
    "# for module in model.modules():\n",
    "#     if isinstance(module, torch.nn.Dropout1d):\n",
    "#         module.train()\n",
    "#         print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = []\n",
    "all_gt = []\n",
    "all_participant_task_chunk_list = []\n",
    "for i in range(0, len(test_data_loader), 6):\n",
    "    for j in [[0, 1], [2, 3], [4, 5]]:\n",
    "        radar_matrix = []\n",
    "        label = []\n",
    "        participant_task_list = []\n",
    "        chunk_id_list = []\n",
    "        with torch.no_grad():\n",
    "            for k in j:\n",
    "                radar_sample, label_sample, participant_task, chunk_id = test_data_loader[i+k]\n",
    "                participant_task_list.append(participant_task)\n",
    "                chunk_id_list.append(int(chunk_id))\n",
    "                radar_matrix.append(radar_sample.to(config.DEVICE))\n",
    "                label.extend(label_sample.squeeze(0).cpu().numpy().tolist())\n",
    "            radar_matrix = torch.cat(radar_matrix, dim=0).unsqueeze(0)[...,:channels//2].permute(0, 2, 3, 1)\n",
    "            radar_matrix = radar_matrix.reshape(radar_matrix.shape[0], -1, radar_matrix.shape[3])\n",
    "            pred = model(radar_matrix)[0].squeeze(0).cpu().numpy()\n",
    "        ##################\n",
    "        assert participant_task_list[0] == participant_task_list[1]\n",
    "        assert chunk_id_list[0] == chunk_id_list[1]-1\n",
    "        ##################\n",
    "        pred = np.array(pred)\n",
    "        label = np.array(label)\n",
    "        all_participant_task_chunk_list.append((participant_task_list[0], chunk_id_list)) \n",
    "        all_pred.append(pred)\n",
    "        all_gt.append(label)\n",
    "        print(participant_task_list[0], chunk_id_list)\n",
    "        # print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = config.TRAIN.DATA.FS\n",
    "ll_cutoff = 8\n",
    "ul_cutoff = 30\n",
    "print(\"Sampling frequency: \", fs)\n",
    "all_pred_hr = []\n",
    "all_gt_hr = []\n",
    "all_goodness = []\n",
    "for pred, gt, (participant_task, chunk_id_list) in zip(all_pred, all_gt, all_participant_task_chunk_list):\n",
    "    print(participant_task, chunk_id_list)\n",
    "    # Norm\n",
    "    pred = ((pred - np.mean(pred)) / np.std(pred))\n",
    "    gt = ((gt - np.mean(gt)) / np.std(gt))\n",
    "    # Detrend and Goodness\n",
    "    goodness = calcMetrics(pred, fs, 0.1, normalize=True)[1][0]\n",
    "    # 1-D gauss blur\n",
    "    # pred = custom_detrend(pred, 100)\n",
    "    # gt = custom_detrend(gt, 100)\n",
    "    pred = np.convolve(pred, np.ones((15))/15, mode='same')\n",
    "    gt = np.convolve(gt, np.ones((15))/15, mode='same')\n",
    "    # Norm\n",
    "    pred = (pred - np.mean(pred)) / np.std(pred)\n",
    "    gt = (gt - np.mean(gt)) / np.std(gt)\n",
    "    # HR\n",
    "    pred_hr = pulse_rate_from_power_spectral_density(pred, fs, ll_cutoff, ul_cutoff, BUTTER_ORDER=2, \n",
    "                                                        DETREND=True, WELCH=False)\n",
    "    gt_hr = pulse_rate_from_power_spectral_density(gt, fs, ll_cutoff, ul_cutoff, BUTTER_ORDER=2, \n",
    "                                                        DETREND=True, WELCH=False)\n",
    "    all_pred_hr.append(pred_hr)\n",
    "    all_gt_hr.append(gt_hr)\n",
    "    all_goodness.append(goodness)\n",
    "    print(f\"| {pred_hr:.2f} - {gt_hr:.2f} | = {abs(pred_hr - gt_hr):.2f} bpm\\t\\t\\t{goodness:.2f}\")\n",
    "    # 1x2 figure with first plot twice as big as second\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5), gridspec_kw={'width_ratios': [5, 2]})\n",
    "    # plt.subplots_adjust(wspace=0.05)\n",
    "    # # plot pred\n",
    "    # ax1.plot(pred, '-', label='pred')\n",
    "    # ax1.plot(gt, '--', label='gt')\n",
    "    # ax1.legend()\n",
    "    # # plot fft\n",
    "    # pred_x, rrpg_fft = sig.periodogram(pred, fs=fs, nfft=18000)\n",
    "    # gt_x, gt_fft = sig.periodogram(gt, fs=fs, nfft=18000)\n",
    "    # # pred_x, rrpg_fft = sig.welch(pred, fs=fs, nperseg=len(pred)//3, nfft=18000)\n",
    "    # # gt_x, gt_fft = sig.welch(gt, fs=fs, nperseg=len(gt)//3, nfft=18000)\n",
    "    # ax2.plot(pred_x*60, rrpg_fft, '-', label='pred')\n",
    "    # ax2.plot(gt_x*60, gt_fft, '--', label='gt')\n",
    "    # ax2.legend()\n",
    "    # ax2.set_xlim(5, 45)\n",
    "    # ax1.set_title(f\"| {pred_hr:.2f} - {gt_hr:.2f} | = {abs(pred_hr - gt_hr):.2f} bpm         {goodness:.2f}\")\n",
    "    # plt.show()\n",
    "    print(\"-\"*100)\n",
    "\n",
    "all_pred_hr = np.array(all_pred_hr)\n",
    "all_gt_hr = np.array(all_gt_hr)\n",
    "all_goodness = np.array(all_goodness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_metric(pred_values, gt_values):\n",
    "    \"\"\"\n",
    "    Calculate the error metric between predicted and ground truth values.\n",
    "    \"\"\"\n",
    "    # Calculate the mean absolute error\n",
    "    mae = np.mean(np.abs(pred_values - gt_values))\n",
    "    # Calculate the root mean squared error\n",
    "    rmse = np.sqrt(np.mean(np.square(np.abs(pred_values - gt_values))))\n",
    "    # Calculate the mean absolute percentage error\n",
    "    mape = np.mean(np.abs((pred_values - gt_values) / gt_values)) * 100\n",
    "    # Calculate pearson correlation coefficient\n",
    "    r = np.corrcoef(pred_values, gt_values)[0, 1]\n",
    "    return mae, rmse, mape, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = np.abs(all_pred_hr - all_gt_hr)\n",
    "# MAE, RMSE, MAPE, r\n",
    "print(get_error_metric(all_pred_hr, all_gt_hr))\n",
    "# Less than 15 bpm\n",
    "print(np.sum(all_errors < 15), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_errors < 15], all_gt_hr[all_errors < 15]))\n",
    "# Less than 5 bpm\n",
    "print(np.sum(all_errors < 5), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_errors < 5], all_gt_hr[all_errors < 5]))\n",
    "# Goodness > 0.5\n",
    "print(len(all_errors[all_goodness > 0.5]), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_goodness > 0.5], all_gt_hr[all_goodness > 0.5]))\n",
    "# Goodness > 0.4\n",
    "print(len(all_errors[all_goodness > 0.4]), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_goodness > 0.4], all_gt_hr[all_goodness > 0.4]))\n",
    "# 1x2 plot\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_pred_hr, all_gt_hr, 'o', alpha=0.5)\n",
    "plt.xlabel('Predicted HR')\n",
    "plt.ylabel('Ground Truth HR')\n",
    "plt.title('HR Prediction') \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_goodness, all_errors, 'o', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(np.array(all_pred_hr), bins=100, alpha=0.5, label='Predicted HR')\n",
    "plt.hist(np.array(all_gt_hr), bins=100, alpha=0.5, label='GT HR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(len(all_pred), len(all_gt), len(all_participant_task_chunk_list))\n",
    "# save_folder = \"waveforms/resp/test_radar_all/\"\n",
    "# os.makedirs(save_folder, exist_ok=True)\n",
    "# with open(os.path.join(save_folder, \"pred.pickle\"), 'wb') as f:\n",
    "#     pickle.dump({'pred': all_pred, 'gt': all_gt, 'participant_task_chunk_id_list': all_participant_task_chunk_list}, f)\n",
    "# with open(os.path.join(save_folder, \"pred.pickle\"), 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "#     pred = data['pred']\n",
    "#     gt = data['gt']\n",
    "#     participant_task_chunk_id_list = data['participant_task_chunk_id_list']\n",
    "# print(len(pred), len(gt), len(participant_task_chunk_id_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rppg-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
