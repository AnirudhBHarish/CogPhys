{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import scipy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heartpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import signal as sig\n",
    "from scipy import sparse as sp\n",
    "from heartpy.datautils import rolling_mean\n",
    "# Set matplotlib font size\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMetrics(input_data, sampFreq, B, window_size=None, use_harmonic=False, normalize=False):\n",
    "    # define goodness parameters\n",
    "    B1 = 0.75 # low cutoff\n",
    "    B2 = 3 # high cutoff\n",
    "\n",
    "    if window_size is None:\n",
    "        pulseCalcLength = len(input_data)\n",
    "    else:\n",
    "        pulseCalcLength = np.uint32(window_size/(1.0/sampFreq))\n",
    "    pulseRate_result = np.empty(len(input_data)-pulseCalcLength + 1)\n",
    "    goodnessMetric_result = np.empty(len(input_data)-pulseCalcLength + 1)\n",
    "\n",
    "    for i in range(0, len(pulseRate_result)):\n",
    "        window = input_data[i:i+pulseCalcLength]\n",
    "        # sigFreq, sigPower = sig.periodogram(window, fs=sampFreq, nfft=180000)\n",
    "        sigFreq, sigPower = sig.welch(x=window, nperseg=len(window)//3, fs=sampFreq, nfft=180000)\n",
    "        maskFreq = (sigFreq > B1)&(sigFreq<B2)\n",
    "        # sigFreq = sigFreq[maskFreq]\n",
    "        sigPower = sigPower * maskFreq\n",
    "        if use_harmonic:\n",
    "            # harmonic PSD\n",
    "            harmonicsigPower = sigPower[::2]\n",
    "            harmonicsigPower = np.pad(harmonicsigPower, (0, len(sigPower) - len(harmonicsigPower)))\n",
    "            # find peak frequency\n",
    "            peakFreq = sigFreq[np.argmax(sigPower + harmonicsigPower)]\n",
    "        else:\n",
    "            peakFreq = sigFreq[np.argmax(sigPower)]\n",
    "        pulseRate = 60.0*peakFreq\n",
    "        pulseRate_result[i] = pulseRate\n",
    "        # compute goodness\n",
    "        aroundPulseRate = (sigFreq > peakFreq - B) & (sigFreq < peakFreq + B)\n",
    "        withinBandpass = (sigFreq >= B1) & (sigFreq <= B2)\n",
    "        powerPulseRate = np.sum(sigPower[aroundPulseRate])\n",
    "        powerAll = np.sum(sigPower[withinBandpass])\n",
    "        if normalize:\n",
    "            goodnessMetric_result[i] = powerPulseRate / powerAll\n",
    "        else:\n",
    "            goodnessMetric_result[i] = powerPulseRate / (powerAll - powerPulseRate)\n",
    "    timestamps = np.arange(len(pulseRate_result))\n",
    "    return timestamps, goodnessMetric_result, pulseRate_result\n",
    "\n",
    "def custom_detrend(sig, Lambda):\n",
    "    \"\"\"custom_detrend(sig, Lambda) -> filtered_signal\n",
    "    This function applies a detrending filter.\n",
    "    This code is based on the following article \"An advanced detrending method with application\n",
    "    to HRV analysis\". Tarvainen et al., IEEE Trans on Biomedical Engineering, 2002.\n",
    "    *Parameters*\n",
    "      ``sig`` (1d numpy array):\n",
    "        The sig where you want to remove the trend.\n",
    "      ``Lambda`` (int):\n",
    "        The smoothing parameter.\n",
    "    *Returns*\n",
    "      ``filtered_signal`` (1d numpy array):\n",
    "        The detrended sig.\n",
    "    \"\"\"\n",
    "    signal_length = sig.shape[0]\n",
    "\n",
    "    # observation matrix\n",
    "    H = np.identity(signal_length)\n",
    "\n",
    "    # second-order difference matrix\n",
    "\n",
    "    ones = np.ones(signal_length)\n",
    "    minus_twos = -2 * np.ones(signal_length)\n",
    "    diags_data = np.array([ones, minus_twos, ones])\n",
    "    diags_index = np.array([0, 1, 2])\n",
    "    D = sp.spdiags(diags_data, diags_index, (signal_length - 2), signal_length).toarray()\n",
    "    filtered_signal = np.dot((H - np.linalg.inv(H + (Lambda ** 2) * np.dot(D.T, D))), sig)\n",
    "    return filtered_signal\n",
    "\n",
    "def pulse_rate_from_power_spectral_density(pleth_sig: np.array, FS: float,\n",
    "                                           LL_PR: float, UL_PR: float,\n",
    "                                           BUTTER_ORDER: int = 6,\n",
    "                                           DETREND: bool = False,\n",
    "                                           FResBPM: float = 0.1,\n",
    "                                           HARMONIC: bool = False,\n",
    "                                           WELCH = True) -> float:\n",
    "    \"\"\" Function to estimate the pulse rate from the power spectral density of the plethysmography sig.\n",
    "\n",
    "    Args:\n",
    "        pleth_sig (np.array): Plethysmography sig.\n",
    "        FS (float): Sampling frequency.\n",
    "        LL_PR (float): Lower cutoff frequency for the butterworth filtering.\n",
    "        UL_PR (float): Upper cutoff frequency for the butterworth filtering.\n",
    "        BUTTER_ORDER (int, optional): Order of the butterworth filter. Give None to skip filtering. Defaults to 6.\n",
    "        DETREND (bool, optional): Boolena Flag for executing cutsom_detrend. Defaults to False.\n",
    "        FResBPM (float, optional): Frequency resolution. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        pulse_rate (float): _description_\n",
    "    \n",
    "\n",
    "    Daniel McDuff, Ethan Blackford, January 2019\n",
    "    Copyright (c)\n",
    "    Licensed under the MIT License and the RAIL AI License.\n",
    "    \"\"\"\n",
    "\n",
    "    N = (60*FS)/FResBPM\n",
    "\n",
    "    # Detrending + nth order butterworth + periodogram\n",
    "    if DETREND:\n",
    "        pleth_sig = custom_detrend(pleth_sig, 100)\n",
    "    if BUTTER_ORDER:\n",
    "        [b, a] = sig.butter(BUTTER_ORDER, [LL_PR/60, UL_PR/60], btype='bandpass', fs = FS)\n",
    "    pleth_sig = sig.filtfilt(b, a, np.double(pleth_sig))\n",
    "    \n",
    "    # Calculate the PSD and the mask for the desired range\n",
    "    if WELCH:\n",
    "        F, Pxx = sig.welch(x=pleth_sig, nperseg=len(pleth_sig)//3, nfft=N, fs=FS)\n",
    "    else:\n",
    "        F, Pxx = sig.periodogram(x=pleth_sig,  nfft=N, fs=FS);  \n",
    "    FMask = (F >= (LL_PR/60)) & (F <= (UL_PR/60))\n",
    "    \n",
    "    # Calculate predicted pulse rate:\n",
    "    FRange = F * FMask\n",
    "    PRange = Pxx * FMask\n",
    "\n",
    "    if HARMONIC:\n",
    "      harmonicsigPower = PRange[::2]\n",
    "      harmonicsigPower = np.pad(harmonicsigPower, (0, len(PRange) - len(harmonicsigPower)))\n",
    "      harmonicsigPower[0] = 0\n",
    "      MaxInd = np.argmax(PRange+harmonicsigPower)\n",
    "    else:\n",
    "      MaxInd = np.argmax(PRange)\n",
    "    pulse_rate_freq = FRange[MaxInd]\n",
    "    pulse_rate = pulse_rate_freq*60\n",
    "            \n",
    "    return pulse_rate\n",
    "\n",
    "def get_error_metric(pred_values, gt_values):\n",
    "    \"\"\"\n",
    "    Calculate the error metric between predicted and ground truth values.\n",
    "    \"\"\"\n",
    "    # Calculate the mean absolute error\n",
    "    mae = np.mean(np.abs(pred_values - gt_values))\n",
    "    # Calculate the root mean squared error\n",
    "    rmse = np.sqrt(np.mean(np.square(np.abs(pred_values - gt_values))))\n",
    "    # Calculate the mean absolute percentage error\n",
    "    mape = np.mean(np.abs((pred_values - gt_values) / gt_values)) * 100\n",
    "    # Calculate pearson correlation coefficient\n",
    "    r = np.corrcoef(pred_values, gt_values)[0, 1]\n",
    "    return mae, rmse, mape, r\n",
    "\n",
    "def get_ibi(pred, gt, fs=30, smooth_window=7):\n",
    "    if smooth_window:\n",
    "        pred = np.convolve(pred, np.ones((smooth_window))/smooth_window, mode='same')\n",
    "        gt = np.convolve(gt, np.ones((smooth_window))/smooth_window, mode='same')\n",
    "    rol_mean = rolling_mean(pred, windowsize=1, sample_rate = fs)\n",
    "    wd = hp.peakdetection.detect_peaks(pred, rol_mean, ma_perc = 20, sample_rate = fs)\n",
    "    pred_peaks = wd['peaklist']\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(pred, label='Filtered and Smoothed rPPG Signal', color='b')\n",
    "    # plt.plot(pred_peaks, pred[pred_peaks], 'rx', label='Detected Peaks', markersize=10)\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "\n",
    "    rol_mean = rolling_mean(gt, windowsize=1, sample_rate = fs)\n",
    "    wd = hp.peakdetection.detect_peaks(gt, rol_mean, ma_perc = 20, sample_rate = fs)\n",
    "    gt_peaks = wd['peaklist']\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(gt, label='Filtered and Smoothed rPPG Signal', color='b')\n",
    "    # plt.plot(gt_peaks, gt[gt_peaks], 'rx', label='Detected Peaks', markersize=10)\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    pred_ibi = np.diff(pred_peaks)\n",
    "    gt_ibi = np.diff(gt_peaks)\n",
    "    return pred_ibi, gt_ibi\n",
    "\n",
    "def get_filtered_ibi(pred, gt, fs=30, smooth_window=7):\n",
    "    pred_ibi, gt_ibi = get_ibi(pred, gt, fs=fs, smooth_window=smooth_window)\n",
    "    # Filter IBI (read the code above)\n",
    "    pred_q1 = np.percentile(pred_ibi, 25)\n",
    "    pred_q2 = np.percentile(pred_ibi, 50)\n",
    "    pred_q3 = np.percentile(pred_ibi, 75)\n",
    "    pred_iqr = pred_q3 - pred_q1\n",
    "    pred_lower_bound = pred_q1 - 1.5 * pred_iqr\n",
    "    pred_upper_bound = pred_q3 + 1.5 * pred_iqr\n",
    "    pred_filtered_ibi = [x for x in pred_ibi if pred_lower_bound <= x <= pred_upper_bound]\n",
    "    gt_q1 = np.percentile(gt_ibi, 25)\n",
    "    gt_q2 = np.percentile(gt_ibi, 50)\n",
    "    gt_q3 = np.percentile(gt_ibi, 75)\n",
    "    gt_iqr = gt_q3 - gt_q1\n",
    "    gt_lower_bound = gt_q1 - 1.5 * gt_iqr\n",
    "    gt_upper_bound = gt_q3 + 1.5 * gt_iqr\n",
    "    gt_filtered_ibi = [x for x in gt_ibi if gt_lower_bound <= x <= gt_upper_bound]\n",
    "    # Sample to secs\n",
    "    pred_filtered_ibi = np.array(pred_filtered_ibi) * (1/fs)\n",
    "    gt_filtered_ibi = np.array(gt_filtered_ibi) * (1/fs)\n",
    "    return pred_filtered_ibi, gt_filtered_ibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_file = \"waveforms/rppg/test_fusion/pred.pickle\"\n",
    "with open(waveform_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data.keys(), data['participant_task_chunk_id_list']\n",
    "all_pred = data['pred']\n",
    "all_gt = data['gt']\n",
    "all_participant_task_chunk_list = data['participant_task_chunk_id_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_file)\n",
    "metadata['Int Skin Tone'] = metadata['Skin Tone'].replace({'fp1':1,'fp2':2,'fp3':3,'fp4':4,'fp5':5,'fp6':6})\n",
    "# Create a dictionary for participant and skin tone\n",
    "participant_numpy = metadata['Participant'].to_numpy()\n",
    "int_skin_tone_numpy = metadata['Int Skin Tone'].to_numpy()\n",
    "fitzpatrick_dict = {par: ist for par, ist in zip(participant_numpy, int_skin_tone_numpy)}\n",
    "print(len(fitzpatrick_dict), fitzpatrick_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 30\n",
    "ll_cutoff = 40\n",
    "ul_cutoff = 180\n",
    "all_pred_hr = []\n",
    "all_gt_hr = []\n",
    "all_pred_ibi = []\n",
    "all_gt_ibi = []\n",
    "all_goodness = []\n",
    "for pred, gt, (participant_task, chunk_id_list) in zip(all_pred, all_gt, all_participant_task_chunk_list):\n",
    "    # Norm\n",
    "    pred = (pred - np.mean(pred)) / np.std(pred)\n",
    "    gt = (gt - np.mean(gt)) / np.std(gt)\n",
    "    # Detrend and Goodness\n",
    "    goodness = calcMetrics(pred, fs, 0.1, normalize=True)[1][0]\n",
    "    # 1-D gauss blur\n",
    "    pred = custom_detrend(pred, 100)\n",
    "    gt = custom_detrend(gt, 100)\n",
    "    pred = np.convolve(pred, np.ones((7))/7, mode='same')\n",
    "    gt = np.convolve(gt, np.ones((7))/7, mode='same')\n",
    "    # Norm\n",
    "    pred = (pred - np.mean(pred)) / np.std(pred)\n",
    "    gt = (gt - np.mean(gt)) / np.std(gt)\n",
    "    # HR\n",
    "    pred_hr = pulse_rate_from_power_spectral_density(pred, fs, ll_cutoff, ul_cutoff, BUTTER_ORDER=6, \n",
    "                                                        DETREND=False, WELCH=True)\n",
    "    gt_hr = pulse_rate_from_power_spectral_density(gt, fs, ll_cutoff, ul_cutoff, BUTTER_ORDER=6, \n",
    "                                                        DETREND=False, WELCH=True)\n",
    "    all_pred_hr.append(pred_hr)\n",
    "    all_gt_hr.append(gt_hr)\n",
    "    all_goodness.append(goodness)\n",
    "    # IBI\n",
    "    pred_ibi, gt_ibi = get_filtered_ibi(pred, gt, fs=fs, smooth_window=7)\n",
    "    all_pred_ibi.append(np.mean(pred_ibi))\n",
    "    all_gt_ibi.append(np.mean(gt_ibi))\n",
    "    pred_hr_ibi = 60 / np.mean(pred_ibi)\n",
    "    gt_hr_ibi = 60 / np.mean(gt_ibi)\n",
    "all_pred_hr = np.array(all_pred_hr)\n",
    "all_gt_hr = np.array(all_gt_hr)\n",
    "all_goodness = np.array(all_goodness)\n",
    "all_pred_ibi = np.array(all_pred_ibi)\n",
    "all_gt_ibi = np.array(all_gt_ibi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = np.abs(all_pred_hr - all_gt_hr)\n",
    "# MAE, RMSE, MAPE, r\n",
    "mae, rmse, mape, r = get_error_metric(all_pred_hr, all_gt_hr)\n",
    "ibi_error = np.mean(np.abs(all_pred_ibi - all_gt_ibi)) * 1000\n",
    "print(\"MAE, RMSE, MAPE, r, IBI\")\n",
    "print(np.round(mae,2),\"&\",np.round(rmse,2),\"&\",np.round(mape,2),\"&\",np.round(r,2),\"&\",np.round(ibi_error,2),r\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_pred_dict = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[]}\n",
    "fp_gt_dict = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[]}\n",
    "fp_ibi_pred_dict = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[]}\n",
    "fp_ibi_gt_dict = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[]}\n",
    "for pred, gt, pred_ibi , gt_ibi, (participant_task, chunk_id_list) in \\\n",
    "        zip(all_pred_hr, all_gt_hr, all_pred_ibi, all_gt_ibi, all_participant_task_chunk_list):\n",
    "    participant = participant_task.split(\"_\")[0]\n",
    "    skin_tone = fitzpatrick_dict[participant]\n",
    "    fp_pred_dict[skin_tone].append(pred)\n",
    "    fp_gt_dict[skin_tone].append(gt)\n",
    "    fp_ibi_pred_dict[skin_tone].append(pred_ibi)\n",
    "    fp_ibi_gt_dict[skin_tone].append(gt_ibi)\n",
    "# Calculate the error metrics for each skin tone\n",
    "# Combine (1,2) & (3,4) & (5,6)\n",
    "lmd_pred_dict = {'l':[], 'm':[], 'd':[]}\n",
    "lmd_gt_dict = {'l':[], 'm':[], 'd':[]}\n",
    "lmd_ibi_pred_dict = {'l':[], 'm':[], 'd':[]}\n",
    "lmd_ibi_gt_dict = {'l':[], 'm':[], 'd':[]}\n",
    "for key in fp_pred_dict.keys():\n",
    "    if key == 1 or key == 2:\n",
    "        lmd_pred_dict['l'] += fp_pred_dict[key]\n",
    "        lmd_gt_dict['l'] += fp_gt_dict[key]\n",
    "        lmd_ibi_pred_dict['l'] += fp_ibi_pred_dict[key]\n",
    "        lmd_ibi_gt_dict['l'] += fp_ibi_gt_dict[key]\n",
    "    elif key == 3 or key == 4:\n",
    "        lmd_pred_dict['m'] += fp_pred_dict[key]\n",
    "        lmd_gt_dict['m'] += fp_gt_dict[key]\n",
    "        lmd_ibi_pred_dict['m'] += fp_ibi_pred_dict[key]\n",
    "        lmd_ibi_gt_dict['m'] += fp_ibi_gt_dict[key]\n",
    "    elif key == 5 or key == 6:\n",
    "        lmd_pred_dict['d'] += fp_pred_dict[key]\n",
    "        lmd_gt_dict['d'] += fp_gt_dict[key]\n",
    "        lmd_ibi_pred_dict['d'] += fp_ibi_pred_dict[key]\n",
    "        lmd_ibi_gt_dict['d'] += fp_ibi_gt_dict[key]\n",
    "# Calculate the error metrics for each skin tone\n",
    "print()\n",
    "print(\"Skin Tone: MAE, RMSE, MAPE, r, IBI\")\n",
    "l_mae, l_rmse, l_mape, l_r = get_error_metric(np.array(lmd_pred_dict['l']), np.array(lmd_gt_dict['l']))\n",
    "l_ibi = np.mean(np.abs(np.array(lmd_ibi_pred_dict['l']) - np.array(lmd_ibi_gt_dict['l']))) * 1000\n",
    "print(\"Light:\", np.round(l_mae,2),\"&\",np.round(l_rmse,2),\"&\",np.round(l_mape,2),\"&\",np.round(l_r,2),\"&\",np.round(l_ibi,2),r\"\\\\\")\n",
    "m_mae, m_rmse, m_mape, m_r = get_error_metric(np.array(lmd_pred_dict['m']), np.array(lmd_gt_dict['m']))\n",
    "m_ibi = np.mean(np.abs(np.array(lmd_ibi_pred_dict['m']) - np.array(lmd_ibi_gt_dict['m']))) * 1000\n",
    "print(\"Medium:\", np.round(m_mae,2),\"&\",np.round(m_rmse,2),\"&\",np.round(m_mape,2),\"&\",np.round(m_r,2),\"&\",np.round(m_ibi,2),r\"\\\\\")\n",
    "d_mae, d_rmse, d_mape, d_r = get_error_metric(np.array(lmd_pred_dict['d']), np.array(lmd_gt_dict['d']))\n",
    "d_ibi = np.mean(np.abs(np.array(lmd_ibi_pred_dict['d']) - np.array(lmd_ibi_gt_dict['d']))) * 1000\n",
    "print(\"Dark:\", np.round(d_mae,2),\"&\",np.round(d_rmse,2),\"&\",np.round(d_mape,2),\"&\",np.round(d_r,2),\"&\",np.round(d_ibi,2),r\"\\\\\")\n",
    "print()\n",
    "# Check if mae and the weighted avg of the three skin tones are equal\n",
    "weighted_mae = (l_mae*len(lmd_pred_dict['l']) + m_mae*len(lmd_pred_dict['m']) \n",
    "                + d_mae*len(lmd_pred_dict['d'])) / (len(lmd_pred_dict['l']) \n",
    "                                                    + len(lmd_pred_dict['m']) + len(lmd_pred_dict['d']))\n",
    "weighted_ibi = (l_ibi*len(lmd_pred_dict['l']) + m_ibi*len(lmd_pred_dict['m'])\n",
    "                + d_ibi*len(lmd_pred_dict['d'])) / (len(lmd_pred_dict['l']) \n",
    "                                                    + len(lmd_pred_dict['m']) + len(lmd_pred_dict['d']))\n",
    "assert np.isclose(mae, weighted_mae), f\"{mae} != {weighted_mae}\"\n",
    "assert np.isclose(ibi_error, weighted_ibi), f\"{ibi_error} != {weighted_ibi}\"\n",
    "print(\"-\"*100, flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rppg-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
