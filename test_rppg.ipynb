{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autorelead libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import heartpy as hp\n",
    "from heartpy.datautils import rolling_mean\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.signal as sig\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import get_config\n",
    "from dataset import data_loader\n",
    "from neural_methods.model.ContrastPhys import ContrastPhys\n",
    "from neural_methods.model.PhysNet import PhysNet_padding_Encoder_Decoder_MAX\n",
    "from neural_methods.model.FactorizePhys.FactorizePhys import FactorizePhys\n",
    "from neural_methods.model.FactorizePhys.FactorizePhysBig import FactorizePhysBig\n",
    "from neural_methods.model.PhysMamba import PhysMamba\n",
    "from neural_methods.model.ContrastFusion import ContrastFusion\n",
    "from neural_methods.model.PhysFormer import ViT_ST_ST_Compact3_TDC_gra_sharp\n",
    "from neural_methods.model.RhythmFormer import RhythmFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMetrics(input_data, sampFreq, B, window_size=None, use_harmonic=False, normalize=False):\n",
    "    # define goodness parameters\n",
    "    B1 = 0.75 # low cutoff\n",
    "    B2 = 3 # high cutoff\n",
    "\n",
    "    if window_size is None:\n",
    "        pulseCalcLength = len(input_data)\n",
    "    else:\n",
    "        pulseCalcLength = np.uint32(window_size/(1.0/sampFreq))\n",
    "    pulseRate_result = np.empty(len(input_data)-pulseCalcLength + 1)\n",
    "    goodnessMetric_result = np.empty(len(input_data)-pulseCalcLength + 1)\n",
    "\n",
    "    for i in range(0, len(pulseRate_result)):\n",
    "        window = input_data[i:i+pulseCalcLength]\n",
    "        # sigFreq, sigPower = sig.periodogram(window, fs=sampFreq, nfft=180000)\n",
    "        sigFreq, sigPower = sig.welch(x=window, nperseg=len(window)//3, fs=sampFreq, nfft=180000)\n",
    "        maskFreq = (sigFreq > B1)&(sigFreq<B2)\n",
    "        # sigFreq = sigFreq[maskFreq]\n",
    "        sigPower = sigPower * maskFreq\n",
    "        if use_harmonic:\n",
    "            # harmonic PSD\n",
    "            harmonicsigPower = sigPower[::2]\n",
    "            harmonicsigPower = np.pad(harmonicsigPower, (0, len(sigPower) - len(harmonicsigPower)))\n",
    "            # find peak frequency\n",
    "            peakFreq = sigFreq[np.argmax(sigPower + harmonicsigPower)]\n",
    "        else:\n",
    "            peakFreq = sigFreq[np.argmax(sigPower)]\n",
    "        pulseRate = 60.0*peakFreq\n",
    "        pulseRate_result[i] = pulseRate\n",
    "        # compute goodness\n",
    "        aroundPulseRate = (sigFreq > peakFreq - B) & (sigFreq < peakFreq + B)\n",
    "        withinBandpass = (sigFreq >= B1) & (sigFreq <= B2)\n",
    "        powerPulseRate = np.sum(sigPower[aroundPulseRate])\n",
    "        powerAll = np.sum(sigPower[withinBandpass])\n",
    "        if normalize:\n",
    "            goodnessMetric_result[i] = powerPulseRate / powerAll\n",
    "        else:\n",
    "            goodnessMetric_result[i] = powerPulseRate / (powerAll - powerPulseRate)\n",
    "    timestamps = np.arange(len(pulseRate_result))\n",
    "    return timestamps, goodnessMetric_result, pulseRate_result\n",
    "\n",
    "def custom_detrend(sig, Lambda):\n",
    "    \"\"\"custom_detrend(sig, Lambda) -> filtered_signal\n",
    "    This function applies a detrending filter.\n",
    "    This code is based on the following article \"An advanced detrending method with application\n",
    "    to HRV analysis\". Tarvainen et al., IEEE Trans on Biomedical Engineering, 2002.\n",
    "    *Parameters*\n",
    "      ``sig`` (1d numpy array):\n",
    "        The sig where you want to remove the trend.\n",
    "      ``Lambda`` (int):\n",
    "        The smoothing parameter.\n",
    "    *Returns*\n",
    "      ``filtered_signal`` (1d numpy array):\n",
    "        The detrended sig.\n",
    "    \"\"\"\n",
    "    signal_length = sig.shape[0]\n",
    "\n",
    "    # observation matrix\n",
    "    H = np.identity(signal_length)\n",
    "\n",
    "    # second-order difference matrix\n",
    "\n",
    "    ones = np.ones(signal_length)\n",
    "    minus_twos = -2 * np.ones(signal_length)\n",
    "    diags_data = np.array([ones, minus_twos, ones])\n",
    "    diags_index = np.array([0, 1, 2])\n",
    "    D = sp.spdiags(diags_data, diags_index, (signal_length - 2), signal_length).toarray()\n",
    "    filtered_signal = np.dot((H - np.linalg.inv(H + (Lambda ** 2) * np.dot(D.T, D))), sig)\n",
    "    return filtered_signal\n",
    "\n",
    "def pulse_rate_from_power_spectral_density(pleth_sig: np.array, FS: float,\n",
    "                                           LL_PR: float, UL_PR: float,\n",
    "                                           BUTTER_ORDER: int = 6,\n",
    "                                           DETREND: bool = False,\n",
    "                                           FResBPM: float = 0.1,\n",
    "                                           HARMONIC: bool = False,\n",
    "                                           WELCH = True) -> float:\n",
    "    \"\"\" Function to estimate the pulse rate from the power spectral density of the plethysmography sig.\n",
    "\n",
    "    Args:\n",
    "        pleth_sig (np.array): Plethysmography sig.\n",
    "        FS (float): Sampling frequency.\n",
    "        LL_PR (float): Lower cutoff frequency for the butterworth filtering.\n",
    "        UL_PR (float): Upper cutoff frequency for the butterworth filtering.\n",
    "        BUTTER_ORDER (int, optional): Order of the butterworth filter. Give None to skip filtering. Defaults to 6.\n",
    "        DETREND (bool, optional): Boolena Flag for executing cutsom_detrend. Defaults to False.\n",
    "        FResBPM (float, optional): Frequency resolution. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        pulse_rate (float): _description_\n",
    "    \n",
    "\n",
    "    Daniel McDuff, Ethan Blackford, January 2019\n",
    "    Copyright (c)\n",
    "    Licensed under the MIT License and the RAIL AI License.\n",
    "    \"\"\"\n",
    "\n",
    "    N = (60*FS)/FResBPM\n",
    "\n",
    "    # Detrending + nth order butterworth + periodogram\n",
    "    if DETREND:\n",
    "        pleth_sig = custom_detrend(pleth_sig, 100)\n",
    "    if BUTTER_ORDER:\n",
    "        [b, a] = sig.butter(BUTTER_ORDER, [LL_PR/60, UL_PR/60], btype='bandpass', fs = FS)\n",
    "    pleth_sig = sig.filtfilt(b, a, np.double(pleth_sig))\n",
    "    \n",
    "    # Calculate the PSD and the mask for the desired range\n",
    "    if WELCH:\n",
    "        F, Pxx = sig.welch(x=pleth_sig, nperseg=len(pleth_sig)//3, nfft=N, fs=FS)\n",
    "    else:\n",
    "        F, Pxx = sig.periodogram(x=pleth_sig,  nfft=N, fs=FS);  \n",
    "    FMask = (F >= (LL_PR/60)) & (F <= (UL_PR/60))\n",
    "    \n",
    "    # Calculate predicted pulse rate:\n",
    "    FRange = F * FMask\n",
    "    PRange = Pxx * FMask\n",
    "\n",
    "    if HARMONIC:\n",
    "      harmonicsigPower = PRange[::2]\n",
    "      harmonicsigPower = np.pad(harmonicsigPower, (0, len(PRange) - len(harmonicsigPower)))\n",
    "      harmonicsigPower[0] = 0\n",
    "      MaxInd = np.argmax(PRange+harmonicsigPower)\n",
    "    else:\n",
    "      MaxInd = np.argmax(PRange)\n",
    "    pulse_rate_freq = FRange[MaxInd]\n",
    "    pulse_rate = pulse_rate_freq*60\n",
    "            \n",
    "    return pulse_rate\n",
    "\n",
    "\n",
    "def get_ibi(pred, gt, fs=30, smooth_window=7):\n",
    "    if smooth_window:\n",
    "        pred = np.convolve(pred, np.ones((smooth_window))/smooth_window, mode='same')\n",
    "        gt = np.convolve(gt, np.ones((smooth_window))/smooth_window, mode='same')\n",
    "    rol_mean = rolling_mean(pred, windowsize=1, sample_rate = fs)\n",
    "    wd = hp.peakdetection.detect_peaks(pred, rol_mean, ma_perc = 20, sample_rate = fs)\n",
    "    pred_peaks = wd['peaklist']\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(pred, label='Filtered and Smoothed rPPG Signal', color='b')\n",
    "    # plt.plot(pred_peaks, pred[pred_peaks], 'rx', label='Detected Peaks', markersize=10)\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "\n",
    "    rol_mean = rolling_mean(gt, windowsize=1, sample_rate = fs)\n",
    "    wd = hp.peakdetection.detect_peaks(gt, rol_mean, ma_perc = 20, sample_rate = fs)\n",
    "    gt_peaks = wd['peaklist']\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(gt, label='Filtered and Smoothed rPPG Signal', color='b')\n",
    "    # plt.plot(gt_peaks, gt[gt_peaks], 'rx', label='Detected Peaks', markersize=10)\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    pred_ibi = np.diff(pred_peaks)\n",
    "    gt_ibi = np.diff(gt_peaks)\n",
    "    return pred_ibi, gt_ibi\n",
    "\n",
    "def get_filtered_ibi(pred, gt, fs=30, smooth_window=7):\n",
    "    pred_ibi, gt_ibi = get_ibi(pred, gt, fs=fs, smooth_window=smooth_window)\n",
    "    # Filter IBI (read the code above)\n",
    "    pred_q1 = np.percentile(pred_ibi, 25)\n",
    "    pred_q2 = np.percentile(pred_ibi, 50)\n",
    "    pred_q3 = np.percentile(pred_ibi, 75)\n",
    "    pred_iqr = pred_q3 - pred_q1\n",
    "    pred_lower_bound = pred_q1 - 1.5 * pred_iqr\n",
    "    pred_upper_bound = pred_q3 + 1.5 * pred_iqr\n",
    "    pred_filtered_ibi = [x for x in pred_ibi if pred_lower_bound <= x <= pred_upper_bound]\n",
    "    gt_q1 = np.percentile(gt_ibi, 25)\n",
    "    gt_q2 = np.percentile(gt_ibi, 50)\n",
    "    gt_q3 = np.percentile(gt_ibi, 75)\n",
    "    gt_iqr = gt_q3 - gt_q1\n",
    "    gt_lower_bound = gt_q1 - 1.5 * gt_iqr\n",
    "    gt_upper_bound = gt_q3 + 1.5 * gt_iqr\n",
    "    gt_filtered_ibi = [x for x in gt_ibi if gt_lower_bound <= x <= gt_upper_bound]\n",
    "    # Sample to secs\n",
    "    pred_filtered_ibi = np.array(pred_filtered_ibi) * (1/fs)\n",
    "    gt_filtered_ibi = np.array(gt_filtered_ibi) * (1/fs)\n",
    "    return pred_filtered_ibi, gt_filtered_ibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # config_file = 'configs/train_configs/CogPhys_CONTRASTPHYS_BASIC.yaml'\n",
    "    # config_file = 'configs/train_configs/CogPhys_PHYSNET_BASIC.yaml'\n",
    "    # config_file = 'configs/train_configs/CogPhys_FactorizePhys_BASIC.yaml'\n",
    "    # config_file = 'configs/train_configs/CogPhys_PHYSMAMBA_BASIC.yaml'\n",
    "    # config_file = 'configs/train_configs/CogPhys_PHYSFORMER_BASIC.yaml'\n",
    "    # config_file = 'configs/train_configs/CogPhys_RHYTHMFORMER_BASIC.yaml'\n",
    "    config_file = 'configs/train_configs/CogPhys_Fusion_BASIC.yaml'\n",
    "    cached_path = None\n",
    "    preprocess = None\n",
    "    lr = None\n",
    "    model_file_name = None\n",
    "\n",
    "args = Args()\n",
    "config = get_config(args)\n",
    "# print('Configuration:')\n",
    "# print(config, end='\\n\\n')\n",
    "data_loader_dict = dict() # dictionary of data loaders \n",
    "train_loader = data_loader.CogPhysLoader.CogPhysLoader\n",
    "print(config.DEVICE)\n",
    "train_data_loader = train_loader(\n",
    "    name=\"train\",\n",
    "    data_path=config.TRAIN.DATA.DATA_PATH,\n",
    "    config_data=config.TRAIN.DATA,\n",
    "    device=config.DEVICE)\n",
    "data_loader_dict['train'] = DataLoader(\n",
    "    dataset=train_data_loader,\n",
    "    num_workers=2,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "print(); print()\n",
    "\n",
    "valid_loader = data_loader.CogPhysLoader.CogPhysLoader\n",
    "print(config.DEVICE)\n",
    "valid_data_loader = valid_loader(\n",
    "    name=\"valid\",\n",
    "    data_path=config.VALID.DATA.DATA_PATH,\n",
    "    config_data=config.VALID.DATA,\n",
    "    device=config.DEVICE)\n",
    "data_loader_dict['valid'] = DataLoader(\n",
    "    dataset=valid_data_loader,\n",
    "    num_workers=2,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "print(); print()\n",
    "\n",
    "test_loader = data_loader.CogPhysLoader.CogPhysLoader\n",
    "print(config.DEVICE)\n",
    "test_data_loader = test_loader(\n",
    "    name=\"test\",\n",
    "    data_path=config.TEST.DATA.DATA_PATH,\n",
    "    config_data=config.TEST.DATA,\n",
    "    device=config.DEVICE)\n",
    "data_loader_dict['test'] = DataLoader(\n",
    "    dataset=test_data_loader,\n",
    "    num_workers=4,\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader.input_preproc, test_data_loader.label_preproc, test_data_loader.input_keys, test_data_loader.label_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_path = 'runs/exp/rgb_cp+_pre/PreTrainedModels/CogPhys_rPPG_ch3_PhysNet_Epoch34.pth'\n",
    "# load_path = 'runs/exp/rgb_physnet/PreTrainedModels/CogPhys_rPPG_ch3_PhysNet_Epoch49.pth'\n",
    "# load_path = 'runs/exp/rgb_fsam/PreTrainedModels/CogPhys_rPPG_ch3_PhysNet_Epoch49.pth'\n",
    "# load_path = 'runs/exp/nir_mamba_pre/PreTrainedModels/CogPhys_rPPG_ch3_PhysNet_Epoch49.pth'\n",
    "# load_path = 'runs/exp/RGB_PhysFormer/PreTrainedModels/CogPhys_rPPG_ch3_PhysFormer_Epoch39.pth'\n",
    "# load_path = 'runs/exp/NIR_RhythmFormer/PreTrainedModels/CogPhys_rPPG_ch1_RhythmFormer_Epoch29.pth'\n",
    "load_path = 'runs/exp/fusion_rppg_early_mid_pre_nir/PreTrainedModels/CogPhys_rPPG_ch3_PhysNet_Epoch49.pth'\n",
    "if config.MODEL.NAME == 'ContrastPhys':\n",
    "    model = ContrastPhys(S=config.MODEL.CONTRASTPHYS.S).to(config.DEVICE).eval()\n",
    "elif config.MODEL.NAME == 'ContrastFusion':\n",
    "    model = ContrastFusion(S=config.MODEL.CONTRASTFUSION.S).to(config.DEVICE).eval()\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(1)))\n",
    "elif config.MODEL.NAME == 'Physnet':\n",
    "    model = PhysNet_padding_Encoder_Decoder_MAX(frames=900).to(config.DEVICE).eval()\n",
    "elif config.MODEL.NAME == 'PhysMamba': \n",
    "    model = PhysMamba(frames=900).to(config.DEVICE).eval()\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(1)))\n",
    "elif config.MODEL.NAME == 'FactorizePhys':\n",
    "    md_config = {}\n",
    "    md_config[\"FRAME_NUM\"] = config.MODEL.FactorizePhys.FRAME_NUM\n",
    "    md_config[\"MD_TYPE\"] = config.MODEL.FactorizePhys.MD_TYPE\n",
    "    md_config[\"MD_FSAM\"] = False\n",
    "    md_config[\"MD_TRANSFORM\"] = config.MODEL.FactorizePhys.MD_TRANSFORM\n",
    "    md_config[\"MD_S\"] = config.MODEL.FactorizePhys.MD_S\n",
    "    md_config[\"MD_R\"] = config.MODEL.FactorizePhys.MD_R\n",
    "    md_config[\"MD_STEPS\"] = config.MODEL.FactorizePhys.MD_STEPS\n",
    "    md_config[\"MD_INFERENCE\"] = config.MODEL.FactorizePhys.MD_INFERENCE\n",
    "    md_config[\"MD_RESIDUAL\"] = config.MODEL.FactorizePhys.MD_RESIDUAL\n",
    "    if config.MODEL.FactorizePhys.TYPE.lower() == \"standard\": model_object = FactorizePhys\n",
    "    elif config.MODEL.FactorizePhys.TYPE.lower() == \"big\": model_object = FactorizePhysBig\n",
    "    model = model_object(frames=config.MODEL.FactorizePhys.FRAME_NUM, md_config=md_config, \n",
    "                         in_channels=config.MODEL.FactorizePhys.CHANNELS,\n",
    "                         dropout=config.MODEL.DROP_RATE, device=config.DEVICE).eval()\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(1)))\n",
    "elif config.MODEL.NAME == 'PhysFormer':\n",
    "    model = ViT_ST_ST_Compact3_TDC_gra_sharp(\n",
    "                image_size=(config.TRAIN.DATA.COGPHYS.SEQ_LENGTH, config.TRAIN.DATA.COGPHYS.H_SIZE,config.TRAIN.DATA.COGPHYS.W_SIZE),\n",
    "                patches=(config.MODEL.PHYSFORMER.PATCH_SIZE,) * 3,\n",
    "                dim=config.MODEL.PHYSFORMER.DIM,\n",
    "                ff_dim=config.MODEL.PHYSFORMER.FF_DIM,\n",
    "                num_heads=config.MODEL.PHYSFORMER.NUM_HEADS,\n",
    "                num_layers=config.MODEL.PHYSFORMER.NUM_LAYERS,\n",
    "                dropout_rate=config.MODEL.DROP_RATE,\n",
    "                theta=config.MODEL.PHYSFORMER.THETA).to(config.DEVICE).eval()\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(1)))\n",
    "elif config.MODEL.NAME == 'RhythmFormer':\n",
    "    model = RhythmFormer().to(config.DEVICE).eval()\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(1)))\n",
    "else:\n",
    "    raise NotImplementedError(f\"Model {config.MODEL.NAME} not implemented.\")\n",
    "model.load_state_dict(torch.load(load_path, map_location=config.DEVICE), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, img_data, gra_sharp=2.0):\n",
    "    if config.MODEL.NAME == 'ContrastPhys':\n",
    "        out = model(img_data)[0][-1].squeeze(0).cpu().numpy()\n",
    "    elif config.MODEL.NAME == 'ContrastFusion':\n",
    "        out = model(img_data)[0][-1].squeeze(0).cpu().numpy()\n",
    "    elif config.MODEL.NAME == 'Physnet':\n",
    "        out = model(img_data)[0].squeeze(0).cpu().numpy()\n",
    "    elif config.MODEL.NAME == 'PhysMamba':\n",
    "        out = model(img_data).squeeze(0).cpu().numpy()\n",
    "    elif config.MODEL.NAME == 'FactorizePhys':\n",
    "        out = model(img_data)[0].squeeze(0).cpu().numpy()\n",
    "    elif config.MODEL.NAME == 'PhysFormer':\n",
    "        out = model(img_data, gra_sharp)[0][-1].squeeze(0).cpu().numpy()\n",
    "    elif config.MODEL.NAME == 'RhythmFormer':\n",
    "        out = model(img_data).squeeze(0).cpu().numpy()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Model {config.MODEL.NAME} not implemented.\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = []\n",
    "all_gt = []\n",
    "all_participant_task_chunk_list = []\n",
    "for i in range(0, len(test_data_loader), 12):\n",
    "    for j in [[0, 1, 4], [5, 6, 7], [8, 9, 10], [11, 2, 3]]:\n",
    "        img = []\n",
    "        label = []\n",
    "        participant_task_list = []\n",
    "        chunk_id_list = []\n",
    "        with torch.no_grad():\n",
    "            for k in j:\n",
    "                img_sample, label_sample, participant_task, chunk_id = test_data_loader[i+k]\n",
    "                participant_task_list.append(participant_task)\n",
    "                chunk_id_list.append(int(chunk_id))\n",
    "                img.append(img_sample.to(config.DEVICE))\n",
    "                label.extend(label_sample.squeeze(0).cpu().numpy().tolist())\n",
    "            img = torch.cat(img, dim=1).unsqueeze(0)\n",
    "            pred = forward_pass(model, img)\n",
    "        if \"v23_read\" == participant_task:\n",
    "            print(\"Skipping\")\n",
    "            continue\n",
    "        ##################\n",
    "        assert participant_task_list[0] == participant_task_list[1]\n",
    "        assert chunk_id_list[0] == chunk_id_list[1]-1\n",
    "        ##################\n",
    "        pred = np.array(pred)\n",
    "        label = np.array(label)\n",
    "        all_participant_task_chunk_list.append((participant_task_list[0], chunk_id_list)) \n",
    "        all_pred.append(pred)\n",
    "        all_gt.append(label)\n",
    "        print(participant_task_list[0], chunk_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = config.TRAIN.DATA.FS\n",
    "ll_cutoff = 40\n",
    "ul_cutoff = 180\n",
    "print(fs, ll_cutoff, ul_cutoff)\n",
    "all_pred_hr = []\n",
    "all_gt_hr = []\n",
    "all_goodness = []\n",
    "all_pred_ibi = []\n",
    "all_gt_ibi = []\n",
    "for pred, gt, (participant_task, chunk_id_list) in zip(all_pred, all_gt, all_participant_task_chunk_list):\n",
    "    print(participant_task, chunk_id_list)\n",
    "    # Norm\n",
    "    pred = (pred - np.mean(pred)) / np.std(pred)\n",
    "    gt = (gt - np.mean(gt)) / np.std(gt)\n",
    "    # Detrend and Goodness\n",
    "    goodness = calcMetrics(pred, fs, 0.1, normalize=True)[1][0]\n",
    "    # 1-D gauss blur\n",
    "    # pred = custom_detrend(pred, 100)\n",
    "    # gt = custom_detrend(gt, 100)\n",
    "    pred = np.convolve(pred, np.ones((7))/7, mode='same')\n",
    "    gt = np.convolve(gt, np.ones((7))/7, mode='same')\n",
    "    # Norm\n",
    "    pred = (pred - np.mean(pred)) / np.std(pred)\n",
    "    gt = (gt - np.mean(gt)) / np.std(gt)\n",
    "    # HR\n",
    "    pred_hr = pulse_rate_from_power_spectral_density(pred, fs, ll_cutoff, ul_cutoff, BUTTER_ORDER=6, \n",
    "                                                        DETREND=False, WELCH=True)\n",
    "    gt_hr = pulse_rate_from_power_spectral_density(gt, fs, ll_cutoff, ul_cutoff, BUTTER_ORDER=6, \n",
    "                                                        DETREND=False, WELCH=True)\n",
    "    all_pred_hr.append(pred_hr)\n",
    "    all_gt_hr.append(gt_hr)\n",
    "    all_goodness.append(goodness)\n",
    "    print(f\"| {pred_hr:.2f} - {gt_hr:.2f} | = {abs(pred_hr - gt_hr):.2f} bpm\\t\\t\\t{goodness:.2f}\")\n",
    "    pred_ibi, gt_ibi = get_filtered_ibi(pred, gt, fs=fs, smooth_window=7)\n",
    "    all_pred_ibi.append(np.mean(pred_ibi))\n",
    "    all_gt_ibi.append(np.mean(gt_ibi))\n",
    "    print(f\"IBI: | {np.mean(pred_ibi)} - {np.mean(gt_ibi)} | = {abs(np.mean(pred_ibi) - np.mean(gt_ibi))} secs\")\n",
    "    # 1x2 figure with first plot twice as big as second\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5), gridspec_kw={'width_ratios': [5, 2]})\n",
    "    # plt.subplots_adjust(wspace=0.05)\n",
    "    # # plot pred\n",
    "    # ax1.plot(pred, '-', label='pred')\n",
    "    # ax1.plot(gt, '--', label='gt')\n",
    "    # ax1.legend()\n",
    "    # # plot fft\n",
    "    # pred_x, rrpg_fft = sig.periodogram(pred, fs=fs, nfft=18000)\n",
    "    # gt_x, gt_fft = sig.periodogram(gt, fs=fs, nfft=18000)\n",
    "    # # pred_x, rrpg_fft = sig.welch(pred, fs=fs, nperseg=len(pred)//3, nfft=18000)\n",
    "    # # gt_x, gt_fft = sig.welch(gt, fs=fs, nperseg=len(gt)//3, nfft=18000)\n",
    "    # ax2.plot(pred_x*60, rrpg_fft, '-', label='pred')\n",
    "    # ax2.plot(gt_x*60, gt_fft, '--', label='gt')\n",
    "    # ax2.legend()\n",
    "    # ax2.set_xlim(5, 45)\n",
    "    # ax1.set_title(f\"| {pred_hr:.2f} - {gt_hr:.2f} | = {abs(pred_hr - gt_hr):.2f} bpm         {goodness:.2f}\")\n",
    "    # plt.show()\n",
    "    print(\"-\"*100)\n",
    "\n",
    "all_pred_hr = np.array(all_pred_hr)\n",
    "all_gt_hr = np.array(all_gt_hr)\n",
    "all_goodness = np.array(all_goodness)\n",
    "all_pred_ibi = np.array(all_pred_ibi)\n",
    "all_gt_ibi = np.array(all_gt_ibi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_metric(pred_values, gt_values):\n",
    "    \"\"\"\n",
    "    Calculate the error metric between predicted and ground truth values.\n",
    "    \"\"\"\n",
    "    # Calculate the mean absolute error\n",
    "    mae = np.mean(np.abs(pred_values - gt_values))\n",
    "    # Calculate the root mean squared error\n",
    "    rmse = np.sqrt(np.mean(np.square(np.abs(pred_values - gt_values))))\n",
    "    # Calculate the mean absolute percentage error\n",
    "    mape = np.mean(np.abs((pred_values - gt_values) / gt_values)) * 100\n",
    "    # Calculate pearson correlation coefficient\n",
    "    r = np.corrcoef(pred_values, gt_values)[0, 1]\n",
    "    return mae, rmse, mape, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = np.abs(all_pred_hr - all_gt_hr)\n",
    "# MAE, RMSE, MAPE, r\n",
    "mae, rmse, mape, r = get_error_metric(all_pred_hr, all_gt_hr)\n",
    "ibi_error = np.mean(np.abs(all_pred_ibi - all_gt_ibi)) * 1000\n",
    "print(\"MAE, RMSE, MAPE, r, IBI\")\n",
    "print(np.round(mae,2),\"&\",np.round(rmse,2),\"&\",np.round(mape,2),\"&\",np.round(r,2),\"&\",np.round(ibi_error,2),r\"\\\\\")\n",
    "# Less than 15 bpm\n",
    "print(np.sum(all_errors < 15), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_errors < 15], all_gt_hr[all_errors < 15]))\n",
    "# Less than 5 bpm\n",
    "print(np.sum(all_errors < 5), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_errors < 5], all_gt_hr[all_errors < 5]))\n",
    "# Goodness > 0.5\n",
    "print(len(all_errors[all_goodness > 0.5]), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_goodness > 0.5], all_gt_hr[all_goodness > 0.5]))\n",
    "# Goodness > 0.4\n",
    "print(len(all_errors[all_goodness > 0.4]), len(all_errors))\n",
    "print(get_error_metric(all_pred_hr[all_goodness > 0.4], all_gt_hr[all_goodness > 0.4]))\n",
    "# 1x2 plot\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_pred_hr, all_gt_hr, 'o', alpha=0.5)\n",
    "plt.xlabel('Predicted HR')\n",
    "plt.ylabel('Ground Truth HR')\n",
    "plt.title('HR Prediction') \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_goodness, all_errors, 'o', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(np.array(all_pred_hr), bins=100, alpha=0.5, label='Predicted HR')\n",
    "plt.hist(np.array(all_gt_hr), bins=100, alpha=0.5, label='GT HR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(all_pred), len(all_gt), len(all_participant_task_chunk_list))\n",
    "# save_folder = \"waveforms/fusion/\"\n",
    "# os.makedirs(save_folder, exist_ok=True)\n",
    "# with open(os.path.join(save_folder, \"pred.pickle\"), 'wb') as f:\n",
    "#     pickle.dump({'pred': all_pred, 'gt': all_gt, 'participant_task_chunk_id_list': all_participant_task_chunk_list}, f)\n",
    "# with open(os.path.join(save_folder, \"pred.pickle\"), 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "#     pred = data['pred']\n",
    "#     gt = data['gt']\n",
    "#     participant_task_chunk_id_list = data['participant_task_chunk_id_list']\n",
    "# print(len(pred), len(gt), len(participant_task_chunk_id_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rppg-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
